{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c879503",
   "metadata": {},
   "source": [
    "### RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6377b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vashusingh/Documents/Coding/project2/AnyData_Rag_Pipeline/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a312dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf\n",
      "  ✓ Loaded 25 pages\n",
      "\n",
      "Processing: Final-Web-Version-Report-AI-Agents.pdf\n",
      "  ✓ Loaded 116 pages\n",
      "\n",
      "Total documents loaded: 141\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96748c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab6b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b75a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe92ea",
   "metadata": {},
   "source": [
    "### embedding And vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ae3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "543614c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x158224d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c9e3b",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c276d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x158223710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bde24ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 430 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (430, 384)\n",
      "Adding 430 documents to vector store...\n",
      "Successfully added 430 documents to vector store\n",
      "Total documents in collection: 860\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498acd10",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351730b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x169c44dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e78529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Learning through inter-action'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_625150f9_39',\n",
       "  'content': 'time decision-making systems.\\nInstruction Fine-Tuning: This process ensures that agents\\nunderstand and execute nuanced directives, enabling them to\\nperform multi-step tasks with high precision and adaptability.\\nD. TRAINING AND EVALUATION TECHNIQUES\\nTraining Agentic AI systems requires techniques that allow\\nagents to learn from interactions with complex environments.\\nCommon training techniques include simulation-based train-\\ning, curriculum learning, and multi-task learning.\\n• Simulation-Based Training: Simulations give students\\na safe context to investigate numerous situations without\\nreal-world consequences [24]. This is very effective in\\nreinforcement learning [25] as it allows agents to design\\npolicies that are transferable to the real task.\\n• Curriculum Learning: Structure tasks in increasing\\norder of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is',\n",
       "  'metadata': {'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'trapped': 'False',\n",
       "   'file_type': 'pdf',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'doc_index': 39,\n",
       "   'total_pages': 25,\n",
       "   'page_label': '6',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'page': 5,\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ieee issue id': '6514899',\n",
       "   'ieee publication id': '6287639',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'content_length': 978,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'ieee article id': '10849561'},\n",
       "  'similarity_score': 0.06779652833938599,\n",
       "  'distance': 0.932203471660614,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_a79e4a34_39',\n",
       "  'content': 'time decision-making systems.\\nInstruction Fine-Tuning: This process ensures that agents\\nunderstand and execute nuanced directives, enabling them to\\nperform multi-step tasks with high precision and adaptability.\\nD. TRAINING AND EVALUATION TECHNIQUES\\nTraining Agentic AI systems requires techniques that allow\\nagents to learn from interactions with complex environments.\\nCommon training techniques include simulation-based train-\\ning, curriculum learning, and multi-task learning.\\n• Simulation-Based Training: Simulations give students\\na safe context to investigate numerous situations without\\nreal-world consequences [24]. This is very effective in\\nreinforcement learning [25] as it allows agents to design\\npolicies that are transferable to the real task.\\n• Curriculum Learning: Structure tasks in increasing\\norder of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is',\n",
       "  'metadata': {'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'content_length': 978,\n",
       "   'page': 5,\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'ieee article id': '10849561',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'page_label': '6',\n",
       "   'doc_index': 39,\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': 'False',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'ieee issue id': '6514899',\n",
       "   'ieee publication id': '6287639',\n",
       "   'total_pages': 25},\n",
       "  'similarity_score': 0.06779652833938599,\n",
       "  'distance': 0.932203471660614,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_9098e3cd_121',\n",
       "  'content': \"to an alternative environment (the outside) and assume the\\nknowledge of moving within the outside environment. This is\\nbecause AI can now learn like humans [89] and use its past\\nexperiences in the environment to approach new situations\\n[90].\\nAnother significant approach for enhancing adaptability is\\ncalled transfer learning [91]. It has proved that unlike static\\nmodels trained for a particular purpose, a learning model\\ntrained for one task can perform a similar or even related,\\nyet distinct, task. This method is particularly convenient for\\nAgentic AIs acting in many different operational spheres,\\nenabling the system to leverage its previous lessons instead of\\n18 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2025.3532853\",\n",
       "  'metadata': {'ieee article id': '10849561',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'page': 17,\n",
       "   'total_pages': 25,\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'doc_index': 121,\n",
       "   'content_length': 915,\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': 'False',\n",
       "   'ieee issue id': '6514899',\n",
       "   'ieee publication id': '6287639',\n",
       "   'page_label': '18',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00'},\n",
       "  'similarity_score': 0.06665974855422974,\n",
       "  'distance': 0.9333402514457703,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_69a78cba_121',\n",
       "  'content': \"to an alternative environment (the outside) and assume the\\nknowledge of moving within the outside environment. This is\\nbecause AI can now learn like humans [89] and use its past\\nexperiences in the environment to approach new situations\\n[90].\\nAnother significant approach for enhancing adaptability is\\ncalled transfer learning [91]. It has proved that unlike static\\nmodels trained for a particular purpose, a learning model\\ntrained for one task can perform a similar or even related,\\nyet distinct, task. This method is particularly convenient for\\nAgentic AIs acting in many different operational spheres,\\nenabling the system to leverage its previous lessons instead of\\n18 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2025.3532853\",\n",
       "  'metadata': {'content_length': 915,\n",
       "   'page_label': '18',\n",
       "   'page': 17,\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'trapped': 'False',\n",
       "   'ieee publication id': '6287639',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'doc_index': 121,\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'ieee issue id': '6514899',\n",
       "   'total_pages': 25,\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'ieee article id': '10849561',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf'},\n",
       "  'similarity_score': 0.06665974855422974,\n",
       "  'distance': 0.9333402514457703,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_c022b958_47',\n",
       "  'content': 'and Multi-Task Learning which allows agents to carry\\nout multiple tasks at a time. Training or evaluating\\nagents in the simulated environment is done using\\nOpenAI Gym [28] and Unity ML-Agents [29].\\n4) Computational Tools and Frameworks : The last\\nsubsection discusses more tools or computational frame-\\nworks pertinent to the building process of autonomous\\nAI systems. Tools such as Reinforcement Learning\\n(RL) algorithms can be implemented using TensorFlow\\nAgents, PyMARL, a multi-agent RL library, and Rasa\\n[30], a framework for conversational agents.\\nThe structural breakdown outlined in the paragraphs above\\nportrays the range of methodologies and tools that can be used\\nto create agentic AI systems and how they can also enhance\\nthe adaptability, efficiency, and functionality of autonomous\\nsystems in complex environments.\\nThe methodologies discussed in this section encompass\\ndiverse applications and ethical considerations. Table 6 sum-',\n",
       "  'metadata': {'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'content_length': 944,\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'file_type': 'pdf',\n",
       "   'ieee article id': '10849561',\n",
       "   'ieee issue id': '6514899',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'total_pages': 25,\n",
       "   'trapped': 'False',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'page': 7,\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'ieee publication id': '6287639',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'doc_index': 47,\n",
       "   'page_label': '8',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV'},\n",
       "  'similarity_score': 0.04223376512527466,\n",
       "  'distance': 0.9577662348747253,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Learning through inter-action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8141ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Unified Multi-task Learning Framework'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 4 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_3ae5ee0e_154',\n",
       "  'content': 'pp. 4555–4576, 2021.\\n[27] R. M. Samant, M. R. Bachute, S. Gite, and K. Kotecha, “Framework\\nfor deep learning-based language models using multi-task learning in\\nnatural language understanding: A systematic literature review and future\\ndirections,” IEEE Access, vol. 10, pp. 17 078–17 097, 2022.\\n[28] J. Arroyo, C. Manna, F. Spiessens, and L. Helsen, “An open-ai gym\\nenvironment for the building optimization testing (boptest) framework,”\\nin Building Simulation 2021, vol. 17. IBPSA, 2021, pp. 175–182.\\n[29] Y . Song, A. Wojcicki, T. Lukasiewicz, J. Wang, A. Aryan, Z. Xu,\\nM. Xu, Z. Ding, and L. Wu, “Arena: A general evaluation platform and\\nbuilding toolkit for multi-agent intelligence,” in Proceedings of the AAAI\\nconference on artificial intelligence, vol. 34, no. 05, 2020, pp. 7253–7260.\\n[30] X. Kong, G. Wang, and A. Nichol, Conversational AI with Rasa: Build, test,\\nand deploy AI-powered, enterprise-grade virtual assistants and chatbots.\\nPackt Publishing Ltd, 2021.',\n",
       "  'metadata': {'creator': 'LaTeX with hyperref',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': 'False',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'page': 21,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'page_label': '22',\n",
       "   'ieee issue id': '6514899',\n",
       "   'total_pages': 25,\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'content_length': 972,\n",
       "   'ieee publication id': '6287639',\n",
       "   'doc_index': 154,\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'ieee article id': '10849561'},\n",
       "  'similarity_score': 0.0325700044631958,\n",
       "  'distance': 0.9674299955368042,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_7dc40e96_154',\n",
       "  'content': 'pp. 4555–4576, 2021.\\n[27] R. M. Samant, M. R. Bachute, S. Gite, and K. Kotecha, “Framework\\nfor deep learning-based language models using multi-task learning in\\nnatural language understanding: A systematic literature review and future\\ndirections,” IEEE Access, vol. 10, pp. 17 078–17 097, 2022.\\n[28] J. Arroyo, C. Manna, F. Spiessens, and L. Helsen, “An open-ai gym\\nenvironment for the building optimization testing (boptest) framework,”\\nin Building Simulation 2021, vol. 17. IBPSA, 2021, pp. 175–182.\\n[29] Y . Song, A. Wojcicki, T. Lukasiewicz, J. Wang, A. Aryan, Z. Xu,\\nM. Xu, Z. Ding, and L. Wu, “Arena: A general evaluation platform and\\nbuilding toolkit for multi-agent intelligence,” in Proceedings of the AAAI\\nconference on artificial intelligence, vol. 34, no. 05, 2020, pp. 7253–7260.\\n[30] X. Kong, G. Wang, and A. Nichol, Conversational AI with Rasa: Build, test,\\nand deploy AI-powered, enterprise-grade virtual assistants and chatbots.\\nPackt Publishing Ltd, 2021.',\n",
       "  'metadata': {'total_pages': 25,\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'page_label': '22',\n",
       "   'ieee publication id': '6287639',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'ieee article id': '10849561',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'content_length': 972,\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'doc_index': 154,\n",
       "   'ieee issue id': '6514899',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'page': 21,\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': 'False'},\n",
       "  'similarity_score': 0.0325700044631958,\n",
       "  'distance': 0.9674299955368042,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_d001e0ac_40',\n",
       "  'content': \"order of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is\\nfundamental in a multi-goal-oriented environment.\\n• Multi-Task Learning : In multi-task learning [27],\\nagents acquire the capabilities to perform several tasks\\nat once, which expands their generalization abilities over\\nmultiple goals, tasks, and scenarios. The problem is of\\nutmost interest in designing agentic AI systems that are\\nsupposed to tackle multiple objectives in parallel.\\nEvaluation techniques for Agentic AI often include metrics\\nsuch as task success rate, adaptability, resource efficiency, and\\nlong-term goal achievement. Table 5 provides an overview of\\nthese training and evaluation techniques.\\n6 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and\",\n",
       "  'metadata': {'content_length': 926,\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'ieee issue id': '6514899',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'trapped': 'False',\n",
       "   'page_label': '6',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'page': 5,\n",
       "   'doc_index': 40,\n",
       "   'ieee publication id': '6287639',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'ieee article id': '10849561',\n",
       "   'total_pages': 25},\n",
       "  'similarity_score': 0.0030550360679626465,\n",
       "  'distance': 0.9969449639320374,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_ef7ac273_40',\n",
       "  'content': \"order of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is\\nfundamental in a multi-goal-oriented environment.\\n• Multi-Task Learning : In multi-task learning [27],\\nagents acquire the capabilities to perform several tasks\\nat once, which expands their generalization abilities over\\nmultiple goals, tasks, and scenarios. The problem is of\\nutmost interest in designing agentic AI systems that are\\nsupposed to tackle multiple objectives in parallel.\\nEvaluation techniques for Agentic AI often include metrics\\nsuch as task success rate, adaptability, resource efficiency, and\\nlong-term goal achievement. Table 5 provides an overview of\\nthese training and evaluation techniques.\\n6 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and\",\n",
       "  'metadata': {'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'trapped': 'False',\n",
       "   'page': 5,\n",
       "   'ieee article id': '10849561',\n",
       "   'page_label': '6',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'content_length': 926,\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'total_pages': 25,\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'doc_index': 40,\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'ieee issue id': '6514899',\n",
       "   'ieee publication id': '6287639',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.0030550360679626465,\n",
       "  'distance': 0.9969449639320374,\n",
       "  'rank': 4}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Unified Multi-task Learning Framework\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23783e",
   "metadata": {},
   "source": [
    "### RAG Pipeline- VectorDB To LLM Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "449a65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY present: True\n",
      "Key length: 56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Direct path to .env file\n",
    "env_path = '/Users/vashusingh/Documents/Coding/project2/AnyData_Rag_Pipeline/.env'\n",
    "\n",
    "# Read and load the file manually\n",
    "with open(env_path, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Verify\n",
    "print(\"GROQ_API_KEY present:\", bool(os.getenv(\"GROQ_API_KEY\")))\n",
    "print(\"Key length:\", len(os.getenv(\"GROQ_API_KEY\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba4b617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bba05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY present: True\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Set the environment variable directly\n",
    "os.environ['GROQ_API_KEY'] = 'gsk_'\n",
    "print(\"GROQ_API_KEY present:\", bool(os.getenv(\"GROQ_API_KEY\")))\n",
    "\n",
    "class GroqLLM:\n",
    "    def __init__(self, model_name: str = \"gemma2-9b-it\", api_key: str =None):\n",
    "        \"\"\"\n",
    "        Initialize Groq LLM\n",
    "        \n",
    "        Args:\n",
    "            model_name: Groq model name (qwen2-72b-instruct, llama3-70b-8192, etc.)\n",
    "            api_key: Groq API key (or set GROQ_API_KEY environment variable)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key or os.environ.get(\"GROQ_API_KEY\")\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Groq API key is required. Set GROQ_API_KEY environment variable or pass api_key parameter.\")\n",
    "        \n",
    "        self.llm = ChatGroq(\n",
    "            groq_api_key=self.api_key,\n",
    "            model_name=self.model_name,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized Groq LLM with model: {self.model_name}\")\n",
    "\n",
    "    def generate_response(self, query: str, context: str, max_length: int = 500) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using retrieved context\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved document context\n",
    "            max_length: Maximum response length\n",
    "            \n",
    "        Returns:\n",
    "            Generated response string\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create prompt template\n",
    "        prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\"You are a helpful AI assistant. Use the following context to answer the question accurately and concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: Provide a clear and informative answer based on the context above. If the context doesn't contain enough information to answer the question, say so.\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Format the prompt\n",
    "        formatted_prompt = prompt_template.format(context=context, question=query)\n",
    "        \n",
    "        try:\n",
    "            # Generate response\n",
    "            messages = [HumanMessage(content=formatted_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "        \n",
    "    def generate_response_simple(self, query: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Simple response generation without complex prompting\n",
    "        \n",
    "        Args:\n",
    "            query: User question\n",
    "            context: Retrieved context\n",
    "            \n",
    "        Returns:\n",
    "            Generated response\n",
    "        \"\"\"\n",
    "        simple_prompt = f\"\"\"Based on this context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            messages = [HumanMessage(content=simple_prompt)]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1fc0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Groq LLM with model: gemma2-9b-it\n",
      "Groq LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq LLM (you'll need to set GROQ_API_KEY environment variable)\n",
    "try:\n",
    "    groq_llm = GroqLLM(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    print(\"Groq LLM initialized successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"Please set your GROQ_API_KEY environment variable to use the LLM.\")\n",
    "    groq_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4110c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Learning through inter-action'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_625150f9_39',\n",
       "  'content': 'time decision-making systems.\\nInstruction Fine-Tuning: This process ensures that agents\\nunderstand and execute nuanced directives, enabling them to\\nperform multi-step tasks with high precision and adaptability.\\nD. TRAINING AND EVALUATION TECHNIQUES\\nTraining Agentic AI systems requires techniques that allow\\nagents to learn from interactions with complex environments.\\nCommon training techniques include simulation-based train-\\ning, curriculum learning, and multi-task learning.\\n• Simulation-Based Training: Simulations give students\\na safe context to investigate numerous situations without\\nreal-world consequences [24]. This is very effective in\\nreinforcement learning [25] as it allows agents to design\\npolicies that are transferable to the real task.\\n• Curriculum Learning: Structure tasks in increasing\\norder of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is',\n",
       "  'metadata': {'total_pages': 25,\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'ieee issue id': '6514899',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'ieee publication id': '6287639',\n",
       "   'page': 5,\n",
       "   'page_label': '6',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'content_length': 978,\n",
       "   'trapped': 'False',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'doc_index': 39,\n",
       "   'ieee article id': '10849561',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV'},\n",
       "  'similarity_score': 0.06779652833938599,\n",
       "  'distance': 0.932203471660614,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_a79e4a34_39',\n",
       "  'content': 'time decision-making systems.\\nInstruction Fine-Tuning: This process ensures that agents\\nunderstand and execute nuanced directives, enabling them to\\nperform multi-step tasks with high precision and adaptability.\\nD. TRAINING AND EVALUATION TECHNIQUES\\nTraining Agentic AI systems requires techniques that allow\\nagents to learn from interactions with complex environments.\\nCommon training techniques include simulation-based train-\\ning, curriculum learning, and multi-task learning.\\n• Simulation-Based Training: Simulations give students\\na safe context to investigate numerous situations without\\nreal-world consequences [24]. This is very effective in\\nreinforcement learning [25] as it allows agents to design\\npolicies that are transferable to the real task.\\n• Curriculum Learning: Structure tasks in increasing\\norder of complexity so that an agent develops basic skills\\nthat can be built upon in new, more complex tasks [26].\\nSuch a structure of progressively more complex tasks is',\n",
       "  'metadata': {'creator': 'LaTeX with hyperref',\n",
       "   'ieee issue id': '6514899',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'trapped': 'False',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'page': 5,\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'content_length': 978,\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '6',\n",
       "   'ieee article id': '10849561',\n",
       "   'doc_index': 39,\n",
       "   'total_pages': 25,\n",
       "   'ieee publication id': '6287639'},\n",
       "  'similarity_score': 0.06779652833938599,\n",
       "  'distance': 0.932203471660614,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_9098e3cd_121',\n",
       "  'content': \"to an alternative environment (the outside) and assume the\\nknowledge of moving within the outside environment. This is\\nbecause AI can now learn like humans [89] and use its past\\nexperiences in the environment to approach new situations\\n[90].\\nAnother significant approach for enhancing adaptability is\\ncalled transfer learning [91]. It has proved that unlike static\\nmodels trained for a particular purpose, a learning model\\ntrained for one task can perform a similar or even related,\\nyet distinct, task. This method is particularly convenient for\\nAgentic AIs acting in many different operational spheres,\\nenabling the system to leverage its previous lessons instead of\\n18 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2025.3532853\",\n",
       "  'metadata': {'doc_index': 121,\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ieee article id': '10849561',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'total_pages': 25,\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'trapped': 'False',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'page': 17,\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'ieee issue id': '6514899',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'page_label': '18',\n",
       "   'content_length': 915,\n",
       "   'ieee publication id': '6287639',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00'},\n",
       "  'similarity_score': 0.06665974855422974,\n",
       "  'distance': 0.9333402514457703,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_69a78cba_121',\n",
       "  'content': \"to an alternative environment (the outside) and assume the\\nknowledge of moving within the outside environment. This is\\nbecause AI can now learn like humans [89] and use its past\\nexperiences in the environment to approach new situations\\n[90].\\nAnother significant approach for enhancing adaptability is\\ncalled transfer learning [91]. It has proved that unlike static\\nmodels trained for a particular purpose, a learning model\\ntrained for one task can perform a similar or even related,\\nyet distinct, task. This method is particularly convenient for\\nAgentic AIs acting in many different operational spheres,\\nenabling the system to leverage its previous lessons instead of\\n18 VOLUME 4, 2016\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2025.3532853\",\n",
       "  'metadata': {'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'content_length': 915,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'page_label': '18',\n",
       "   'ieee issue id': '6514899',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'ieee article id': '10849561',\n",
       "   'page': 17,\n",
       "   'doc_index': 121,\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'trapped': 'False',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'ieee publication id': '6287639',\n",
       "   'total_pages': 25},\n",
       "  'similarity_score': 0.06665974855422974,\n",
       "  'distance': 0.9333402514457703,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_c022b958_47',\n",
       "  'content': 'and Multi-Task Learning which allows agents to carry\\nout multiple tasks at a time. Training or evaluating\\nagents in the simulated environment is done using\\nOpenAI Gym [28] and Unity ML-Agents [29].\\n4) Computational Tools and Frameworks : The last\\nsubsection discusses more tools or computational frame-\\nworks pertinent to the building process of autonomous\\nAI systems. Tools such as Reinforcement Learning\\n(RL) algorithms can be implemented using TensorFlow\\nAgents, PyMARL, a multi-agent RL library, and Rasa\\n[30], a framework for conversational agents.\\nThe structural breakdown outlined in the paragraphs above\\nportrays the range of methodologies and tools that can be used\\nto create agentic AI systems and how they can also enhance\\nthe adaptability, efficiency, and functionality of autonomous\\nsystems in complex environments.\\nThe methodologies discussed in this section encompass\\ndiverse applications and ethical considerations. Table 6 sum-',\n",
       "  'metadata': {'content_length': 944,\n",
       "   'page_label': '8',\n",
       "   'source': '../data/pdf/Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'Agentic AI: Autonomous Intelligence for Complex Goals &#x2013; A Comprehensive Survey',\n",
       "   'ieee article id': '10849561',\n",
       "   'moddate': '2025-01-22T10:36:25-05:00',\n",
       "   'doc_index': 47,\n",
       "   'trapped': 'False',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'total_pages': 25,\n",
       "   'source_file': 'Agentic_AI_Autonomous_Intelligence_for_Complex_Goa.pdf',\n",
       "   'subject': 'IEEE Access; ;PP;99;10.1109/ACCESS.2025.3532853',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
       "   'creationdate': '2025-01-01T22:31:43+00:00',\n",
       "   'ieee publication id': '6287639',\n",
       "   'producer': 'pdfTeX-1.40.26; modified using iText® 7.1.12 ©2000-2020 iText Group NV (AGPL-version); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV',\n",
       "   'page': 7,\n",
       "   'ieee issue id': '6514899'},\n",
       "  'similarity_score': 0.04223376512527466,\n",
       "  'distance': 0.9577662348747253,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get the context from the retriever and pass it to the LLM\n",
    "\n",
    "rag_retriever.retrieve(\"Learning through inter-action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea465ac",
   "metadata": {},
   "source": [
    "### Integration Vectordb Context pipeline With LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a950a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (set your GROQ_API_KEY in environment)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-it\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "## 2. Simple RAG function: retrieve context + generate response\n",
    "def rag_simple(query,retriever,llm,top_k=3):\n",
    "    ## retriever the context\n",
    "    results=retriever.retrieve(query,top_k=top_k)\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    \n",
    "    ## generate the answwer using GROQ LLM\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response=llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df1bf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'how agentic ai is going to solve complex problem?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Agentic AI aims to solve complex problems through **adaptability, advanced decision-making, and planning**, allowing it to operate with minimal human intervention in diverse and complex environments.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"how agentic ai is going to solve complex problem?\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857b1c2",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2832fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Hard Negative Mining Technqiues'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n",
      "Answer: No relevant context found.\n",
      "Sources: []\n",
      "Confidence: 0.0\n",
      "Context Preview: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Hard Negative Mining Technqiues\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa6150d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is attention is all you need'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Answer: No relevant context found.\n",
      "Summary: The provided text does not contain any information that can be summarized.  \n",
      "\n",
      "There is no relevant context to draw upon for a concise summary. \n",
      "\n",
      "\n",
      "\n",
      "History: {'question': 'what is attention is all you need', 'answer': 'No relevant context found.', 'sources': [], 'summary': 'The provided text does not contain any information that can be summarized.  \\n\\nThere is no relevant context to draw upon for a concise summary. \\n\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is attention is all you need\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
